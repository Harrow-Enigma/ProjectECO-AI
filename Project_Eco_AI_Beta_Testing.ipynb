{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Project Eco AI Beta Testing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harrow-Enigma/TeamEngima-ProjectEco-AI/blob/main/Project_Eco_AI_Beta_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK2Ie7F95sad"
      },
      "source": [
        "# Project ECO AI Beta Testing Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKoV7XQJr12x"
      },
      "source": [
        "Copyright 2021 YIDING SONG\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7WXdB25m4-y"
      },
      "source": [
        "!pip install tabulate\n",
        "!curl -o label_classes.py https://raw.githubusercontent.com/Harrow-Enigma/TeamEngima-ProjectEco-AI/main/label_classes.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT8k9Osx8xA4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from label_classes import Label, FloatLabel, IntClass, IntClassMap\n",
        "\n",
        "from datetime import timedelta, timezone\n",
        "from datetime import datetime as dt\n",
        "from tqdm import tqdm\n",
        "import pickle as pkl\n",
        "import requests\n",
        "import json\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV7lITxcn1Oq"
      },
      "source": [
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "mpl.rcParams['axes.titlecolor'] = 'green'\n",
        "mpl.rcParams['axes.labelcolor'] = 'black'\n",
        "mpl.rcParams['xtick.color'] = 'black'\n",
        "mpl.rcParams['ytick.color'] = 'black'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAlxKRL4XAqi"
      },
      "source": [
        "np.random.seed(219)\n",
        "tf.random.set_seed(219)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfU54x-Un209"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXTUeHptMFaI"
      },
      "source": [
        "beta_api_url = 'https://dev-test.projecteco.ml/api/v1/rest/output/forms/'\n",
        "response = requests.get(beta_api_url)\n",
        "json_data = response.json()\n",
        "json_data = json_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RebBNO5SPifB"
      },
      "source": [
        "for k in range(len(json_data)):\n",
        "  try:\n",
        "    _ = json_data[k]['localpollutiondata']\n",
        "    _has_key = True\n",
        "  except:\n",
        "    print('Error: No `localpollutiondata` key')\n",
        "    _has_key = False\n",
        "  \n",
        "  if _has_key:\n",
        "    for pol_key in list(json_data[k]['localpollutiondata']\\\n",
        "                        ['data'].keys()):\n",
        "      json_data[k][pol_key] = json_data[k]['localpollutiondata']\\\n",
        "                                       ['data'][pol_key]['v']\n",
        "    json_data[k].pop('localpollutiondata')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gjcWgTkVwYS"
      },
      "source": [
        "print(json.dumps(json_data, indent=4, sort_keys=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP1QkHo23Ysd"
      },
      "source": [
        "## Defining the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSf0UkjO7o_d"
      },
      "source": [
        "FEATURE_CLASSES = [\n",
        "  FloatLabel('h'), FloatLabel('no2'), FloatLabel('o3'),\n",
        "  FloatLabel('p'), FloatLabel('pm10'), FloatLabel('pm25'),\n",
        "  FloatLabel('t'), FloatLabel('w'), FloatLabel('wg'),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vljxxBffTJKr"
      },
      "source": [
        "LABEL_CLASSES = [\n",
        "  IntClass('Q1 (General feeling)', _key='q1'),\n",
        "  IntClass('Q2 (Concentration)', _key='q2'),\n",
        "  IntClass('Q3 (Work Stress)', _key='q3'),\n",
        "  IntClassMap('Q4 (Dizziness, headaches, shortness of breath)',\n",
        "              {'no': 0, 'yes': 1},\n",
        "              _key='q4'),\n",
        "  IntClassMap('Q5 (Allergic responses)',\n",
        "              {'no': 0, 'yes': 1},\n",
        "              _key='q5')\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hzbl2mi3g6X"
      },
      "source": [
        "## Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7CVYZfnhpQk"
      },
      "source": [
        "def handle_exception(feat_class, timestep_data):\n",
        "  try:\n",
        "    _val = timestep_data[feat_class.key]\n",
        "    if _val is not None:\n",
        "      return feat_class.fwd_call(_val)\n",
        "    return feat_class.fallback\n",
        "  except:\n",
        "    return feat_class.fallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do92xPm2JMpx"
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "for t in json_data:\n",
        "  features.append([handle_exception(c, t)\n",
        "                    for c in FEATURE_CLASSES])\n",
        "  labels.append([handle_exception(c, t)\n",
        "                    for c in LABEL_CLASSES])\n",
        "\n",
        "features = np.array(features, np.float32)\n",
        "labels = np.array(labels, np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF4RrAC6vQMx"
      },
      "source": [
        "def standardize(arr):\n",
        "  m = arr.mean(0)\n",
        "  s = arr.std(0)\n",
        "    \n",
        "  for i in range(len(s)):\n",
        "    if s[i] == 0:\n",
        "      s[i] = 1e-8\n",
        "  \n",
        "  arr = (arr - m)/s\n",
        "  return arr, m, s\n",
        "\n",
        "def destandardize(arr, m, s):\n",
        "  return arr * s + m\n",
        "\n",
        "def rescale(arr, delta=0.01):\n",
        "  arr_max = arr.max(axis=0) + delta\n",
        "  arr_min = arr.min(axis=0) - delta\n",
        "  arr_range = arr_max - arr_min\n",
        "  arr_ofst = (arr_max + arr_min) / 2\n",
        "  return (arr - arr_ofst) / arr_range, arr_ofst, arr_range\n",
        "\n",
        "def descale(arr, arr_ofst, arr_range):\n",
        "  return arr * arr_range + arr_ofst\n",
        "\n",
        "def normalize(arr):\n",
        "  arr_std, m, s = standardize(arr)\n",
        "  arr_norm, o, r = rescale(arr_std)\n",
        "  return arr_norm, m, s, o, r\n",
        "\n",
        "def denormalize(arr, m, s, o, r):\n",
        "  return destandardize(descale(arr, o, r), m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8twPOKxwNv4"
      },
      "source": [
        "(features_norm,\n",
        " features_mean,\n",
        " features_stddv,\n",
        " features_ofst,\n",
        " features_range) = normalize(features)\n",
        "\n",
        "(labels_norm,\n",
        " labels_mean,\n",
        " labels_stddv,\n",
        " labels_ofst,\n",
        " labels_range) = normalize(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4nvu2RlnIGF"
      },
      "source": [
        "'''\n",
        "assert features.all() == denormalize(features_norm, features_mean,\n",
        "                                     features_stddv, features_ofst, features_range).all()\n",
        "assert labels.all() == denormalize(labels_norm, labels_mean,\n",
        "                                   labels_stddv, labels_ofst, labels_range).all()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YStxgvFtpGtq"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKvL8AhtbeXI"
      },
      "source": [
        "dataset_size = len(features_norm)\n",
        "ratio = 9/10\n",
        "train_no = int(ratio * dataset_size)\n",
        "test_no = dataset_size - train_no\n",
        "print('Number of training samples: {}'.format(train_no))\n",
        "print('Number of testing samples: {}'.format(test_no))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzdMDOK8MsAL"
      },
      "source": [
        "train_features_norm = features_norm[:train_no]\n",
        "test_features_norm = features_norm[train_no:]\n",
        "train_labels_norm = labels_norm[:train_no]\n",
        "test_labels_norm = labels_norm[train_no:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzXVu5ju3DH3"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_features_norm, train_labels_norm)\n",
        ").batch(2, drop_remainder=False)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_features_norm, test_labels_norm)\n",
        ").batch(2, drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVoilJ5t0ppw"
      },
      "source": [
        "pkl.dump({\n",
        "    'features': {\n",
        "        'classes': FEATURE_CLASSES,\n",
        "        'mean':    features_mean,\n",
        "        'std_dev': features_stddv,\n",
        "        'offset':  features_ofst,\n",
        "        'range':    features_range\n",
        "    },\n",
        "    'labels': {\n",
        "        'classes': LABEL_CLASSES,\n",
        "        'mean':    labels_mean,\n",
        "        'std_dev': labels_stddv,\n",
        "        'offset':  labels_ofst,\n",
        "        'range':    labels_range\n",
        "    },\n",
        "}, open('beta_data_aux.data', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKtkUZIJdBQH"
      },
      "source": [
        "## Building the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMTrje52P_HZ"
      },
      "source": [
        "class DNNModel(tf.keras.Model):\n",
        "  def __init__(self,\n",
        "               inp_shape: int,\n",
        "               out_shape: int,\n",
        "               units=[32, 64, 64],\n",
        "               name='DNNModel'):\n",
        "    super(DNNModel, self).__init__(name = name)\n",
        "\n",
        "    self.inp_shape = inp_shape\n",
        "    self.out_shape = out_shape\n",
        "    \n",
        "    self.stack = [tf.keras.layers.Dense(i, activation='relu') for i in units]\n",
        "    self.out = tf.keras.layers.Dense(self.out_shape, activation='tanh')\n",
        "  \n",
        "  def call(self, inp):\n",
        "    x = inp\n",
        "    for _layer in self.stack:\n",
        "      x = _layer(x)\n",
        "    return self.out(x)\n",
        "  \n",
        "  def functional(self):\n",
        "    inputs = tf.keras.Input(self.inp_shape)\n",
        "    outputs = self.call(inputs)\n",
        "    return tf.keras.Model(inputs, outputs, name=self.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocLx4tSmh10G"
      },
      "source": [
        "sample_model = DNNModel(\n",
        "    len(FEATURE_CLASSES), len(LABEL_CLASSES)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz4dEi62iTRi"
      },
      "source": [
        "for i in dataset.take(1):\n",
        "  sample_pred = sample_model(tf.expand_dims(i[0], 0))\n",
        "  print('Sample prediction of shape {}:\\n{}'.format(\n",
        "      sample_pred.shape, sample_pred\n",
        "  ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIGJVxGDrJV-"
      },
      "source": [
        "### Model Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea--4kT0iCZ6"
      },
      "source": [
        "sample_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVrQLwQgeyUF"
      },
      "source": [
        "tf.keras.utils.plot_model(sample_model.functional(), to_file=\"model.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KdaPOHNrV1n"
      },
      "source": [
        "## Defining losses and optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZiGmJLBQBBp"
      },
      "source": [
        "mae = tf.keras.losses.MeanAbsoluteError()\n",
        "optim = tf.keras.optimizers.Adam(1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmqBB-Sn9v3H"
      },
      "source": [
        "model = DNNModel(\n",
        "    len(FEATURE_CLASSES), len(LABEL_CLASSES)\n",
        ")\n",
        "model.compile(optimizer = optim, loss = mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2t_KGe2TcVp"
      },
      "source": [
        "## Defining training checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbwP_IJjUW0b"
      },
      "source": [
        "checkpoint_dir = './ProjectECO_Beta_Checkpoints/'\n",
        "\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "  os.mkdir(checkpoint_dir)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_prefix,\n",
        "    save_weights_only = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LlifWinreT4"
      },
      "source": [
        "## TRAINING!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQJ00rrO-wJM"
      },
      "source": [
        "model.fit(train_dataset.repeat(), callbacks=[checkpoint_callback],\n",
        "          steps_per_epoch = 1000, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eAozScagDTh"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNIROPE1ehYo"
      },
      "source": [
        "model.save_weights('beta_weights.h5')\n",
        "model.functional().save('beta_model_func.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibu2DaNvU77L"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "for name in os.listdir('./'):\n",
        "  if not os.path.isdir(name):\n",
        "    files.download(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COelyRrZ5wm0"
      },
      "source": [
        "## Standalone Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7AkZm0Es8u"
      },
      "source": [
        "!pip install tabulate\n",
        "!curl -o label_classes.py https://raw.githubusercontent.com/Harrow-Enigma/TeamEngima-ProjectEco-AI/main/label_classes.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlWkxHhGBRnh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from label_classes import Label, FloatLabel, IntClass, IntClassMap\n",
        "\n",
        "from datetime import timedelta, timezone\n",
        "from datetime import datetime as dt\n",
        "from tabulate import tabulate\n",
        "from tqdm import tqdm\n",
        "import pickle as pkl\n",
        "import requests\n",
        "import json\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbiic9gkJf6G"
      },
      "source": [
        "### Pre-Requisite Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIvTs4z3BZrl"
      },
      "source": [
        "def standardize_on_params(arr, m, s):\n",
        "  return (arr - m)/s\n",
        "\n",
        "def destandardize(arr, m, s):\n",
        "  return arr * s + m\n",
        "\n",
        "def rescale_on_params(arr, arr_ofst, arr_range):\n",
        "  return (arr - arr_ofst) / arr_range\n",
        "\n",
        "def descale(arr, arr_ofst, arr_range):\n",
        "  return arr * arr_range + arr_ofst\n",
        "\n",
        "def normalize_on_params(arr, m, s, o, r):\n",
        "  arr_std = standardize_on_params(arr, m, s)\n",
        "  arr_norm = rescale_on_params(arr_std, o, r)\n",
        "  return arr_norm\n",
        "\n",
        "def denormalize(arr, m, s, o, r):\n",
        "  return destandardize(descale(arr, o, r), m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dof4Wi9uDW6k"
      },
      "source": [
        "obj = pkl.load(open('beta_data_aux.data', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLETwhrJDdIC"
      },
      "source": [
        "FEATURE_CLASSES = obj['features']['classes']\n",
        "features_mean = obj['features']['mean']\n",
        "features_stddv = obj['features']['std_dev']\n",
        "features_ofst = obj['features']['offset']\n",
        "features_range = obj['features']['range']\n",
        "\n",
        "LABEL_CLASSES = obj['labels']['classes']\n",
        "labels_mean = obj['labels']['mean']\n",
        "labels_stddv = obj['labels']['std_dev']\n",
        "labels_ofst = obj['labels']['offset']\n",
        "labels_range = obj['labels']['range']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVh_Vi3UEPqk"
      },
      "source": [
        "model = tf.keras.models.load_model('beta_model_func.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YssPXWxSJeQg"
      },
      "source": [
        "### Pre-Requisite Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0ebq8CMJpQ3"
      },
      "source": [
        "def handle_exception(feat_class, timestep_data):\n",
        "  try:\n",
        "    _val = timestep_data[feat_class.key]\n",
        "    if _val is not None:\n",
        "      return feat_class.fwd_call(_val)\n",
        "    return feat_class.fallback\n",
        "  except:\n",
        "    return feat_class.fallback\n",
        "\n",
        "beta_api_url = 'https://dev-test.projecteco.ml/api/v1/rest/output/forms/'\n",
        "response = requests.get(beta_api_url)\n",
        "json_data = response.json()\n",
        "\n",
        "for k in range(len(json_data)):\n",
        "  try:\n",
        "    _ = json_data[k]['localpollutiondata']\n",
        "    _has_key = True\n",
        "  except:\n",
        "    print('Error: No `localpollutiondata` key')\n",
        "    _has_key = False\n",
        "  \n",
        "  if _has_key:\n",
        "    for pol_key in list(json_data[k]['localpollutiondata']\\\n",
        "                        ['data'].keys()):\n",
        "      json_data[k][pol_key] = json_data[k]['localpollutiondata']\\\n",
        "                                       ['data'][pol_key]['v']\n",
        "    json_data[k].pop('localpollutiondata')\n",
        "  \n",
        "server_features = []\n",
        "server_labels = []\n",
        "\n",
        "for t in json_data:\n",
        "  server_features.append([handle_exception(c, t)\n",
        "                          for c in FEATURE_CLASSES])\n",
        "  server_labels.append([handle_exception(c, t)\n",
        "                        for c in LABEL_CLASSES])\n",
        "\n",
        "server_features = np.array(server_features, np.float32)\n",
        "server_labels = np.array(server_labels, np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaIKlPvJh13"
      },
      "source": [
        "### Visualization Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8cO53ZxEhMK"
      },
      "source": [
        "def visualize_inputs(inps, headers=('Input name', 'Input value')):\n",
        "  data_arr = [[c.name, c.fwd_call(val)] for c, val in zip(FEATURE_CLASSES, inps)]\n",
        "  print(tabulate(data_arr, headers=headers))\n",
        "\n",
        "def visualize_features(feat, headers=('Feature name', 'Feature value')):\n",
        "  data_arr = [[c.name, val] for c, val in zip(FEATURE_CLASSES, feat)]\n",
        "  print(tabulate(data_arr, headers=headers))\n",
        "\n",
        "def visualize_preds(preds, headers=('Prediction name', 'Prediction value')):\n",
        "  data_arr = [[c.name, c.rev_call(val)] for c, val in zip(LABEL_CLASSES, preds)]\n",
        "  print(tabulate(data_arr, headers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m1nsFV_EX9u"
      },
      "source": [
        "def preproc(inps):\n",
        "  feats = np.array([[c.fwd_call(val) for c, val in zip(FEATURE_CLASSES, entry)]\n",
        "                   for entry in inps])\n",
        "  feats_norm = normalize_on_params(feats, features_mean, features_stddv, \n",
        "                                   features_ofst, features_range)\n",
        "  return feats_norm\n",
        "\n",
        "def denorm_preds(preds_norm):\n",
        "  return denormalize(preds_norm, labels_mean, labels_stddv,\n",
        "                     labels_ofst, labels_range)\n",
        "\n",
        "def visualize(inps, see_feats=False):\n",
        "  feats_norm = preproc(inps)\n",
        "  preds_norm = model.predict(feats_norm)\n",
        "  preds = denormalize(preds_norm, labels_mean, labels_stddv,\n",
        "                      labels_ofst, labels_range)\n",
        "  \n",
        "  for e, (i, f, p) in enumerate(zip(inps, feats_norm, preds)):\n",
        "    print('Visualizing input {}'.format(e))\n",
        "    print()\n",
        "    visualize_inputs(i)\n",
        "    print()\n",
        "    if see_feats:\n",
        "      visualize_features(f)\n",
        "      print()\n",
        "    visualize_preds(p)\n",
        "    print('\\n=====================================================================\\n\\n')\n",
        "\n",
        "def compare_vis(inps, labs, see_feats=False):\n",
        "  feats_norm = preproc(inps)\n",
        "  preds_norm = model.predict(feats_norm)\n",
        "  preds = denorm_preds(preds_norm)\n",
        "  \n",
        "  for e, (i, f, p, g) in enumerate(zip(inps, feats_norm, preds, labs)):\n",
        "    print('Visualizing input {}'.format(e))\n",
        "    print()\n",
        "    visualize_inputs(i)\n",
        "    print()\n",
        "    if see_feats:\n",
        "      visualize_features(f)\n",
        "      print()\n",
        "    visualize_preds(p, headers=(\"Prediction Name\", \"Model Output\"))\n",
        "    print()\n",
        "    visualize_preds(g, headers=(\"Prediction Name\", \"Ground Truth\"))\n",
        "    print('\\n==================================================================\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ve_9S_RNhIa"
      },
      "source": [
        "def locate_label_by_name(_name, classes):\n",
        "  for e, i in enumerate(classes):\n",
        "    if i.name == _name:\n",
        "      return e\n",
        "\n",
        "def replace_in_arr(arr, idx, newval):\n",
        "  ret = arr.copy()\n",
        "  ret[idx] = newval\n",
        "  return ret\n",
        "\n",
        "def makegraph(x, y, xlab='', ylab='', title=''):\n",
        "  plt.figure(figsize=(8, 5), dpi=150)\n",
        "  plt.plot(x, y)\n",
        "  plt.xlabel(xlab)\n",
        "  plt.ylabel(ylab)\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "def autorange(featurename, sub_d=100):\n",
        "  feats = server_features[:, locate_label_by_name(featurename,\n",
        "                                                  FEATURE_CLASSES)]\n",
        "  step = (feats.max() - feats.min()) / (sub_d - 1)\n",
        "  return np.arange(feats.min(), feats.max() + step, step)\n",
        "\n",
        "def plot_relation_by_name(featurename,\n",
        "                          labelname,\n",
        "                          _range,\n",
        "                          _vars=server_features[0]):\n",
        "  _vars = server_features[0]\n",
        "  _feat_loc = locate_label_by_name(featurename, FEATURE_CLASSES)\n",
        "  _lab_loc = locate_label_by_name(labelname, LABEL_CLASSES)\n",
        "\n",
        "  _x = [replace_in_arr(_vars, _feat_loc, i) for i in _range]\n",
        "  _y = denorm_preds(model.predict(preproc(_x)))[:, _lab_loc]\n",
        "\n",
        "  makegraph(_range, _y, featurename, labelname,\n",
        "            'How {} responses vary with {} levels'.format(labelname,\n",
        "                                                          featurename))\n",
        "\n",
        "def plot_relation_from_data(featurename,\n",
        "                            labelname):\n",
        "  _x = server_features[:, locate_label_by_name(featurename, FEATURE_CLASSES)]\n",
        "  _y = server_labels[:, locate_label_by_name(labelname, LABEL_CLASSES)]\n",
        "\n",
        "  _idx = np.argsort(_x)\n",
        "  _x = _x[_idx]\n",
        "  _y = _y[_idx]\n",
        "\n",
        "  makegraph(_x, _y, featurename, labelname,\n",
        "            'How {} responses vary with {} levels'.format(labelname,\n",
        "                                                          featurename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oTYbTwFJkHb"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGzv7dJQI7Za"
      },
      "source": [
        "visualize(server_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbaVcRCmLLx1"
      },
      "source": [
        "compare_vis(server_features, server_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYo0OXTzOccd"
      },
      "source": [
        "server_features[:, locate_label_by_name('pm10', FEATURE_CLASSES)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOVKFF2cNC-I"
      },
      "source": [
        "# How stress levels vary with PM2.5 concentration,\n",
        "# assuming that all other values follow server_features[0]\n",
        "plot_relation_by_name('pm10', 'Q3 (Work Stress)',\n",
        "                      autorange('pm25', 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zyVA9SzpLA7"
      },
      "source": [
        "plot_relation_by_name('no2', 'Q2 (Concentration)',\n",
        "                      autorange('pm25', 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVC151bHqAAV"
      },
      "source": [
        "plot_relation_from_data('no2', 'Q2 (Concentration)')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}